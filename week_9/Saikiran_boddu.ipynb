{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHfW3IvzZJe_"
      },
      "source": [
        "Venkatesh\n",
        "\n",
        "\n",
        "Week 09 Assignment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNbPK0taZNOO"
      },
      "source": [
        "\n",
        "\n",
        "1. Among the different classification models included in the Python notebook, which model had the best overall performance? Support your response by referencing appropriate evidence.\n",
        "\n",
        "The notebook displays results showing different model comparisons through their training accuracy and test accuracy scores. The best assessment method to determine model performance involves checking training and test accuracy levels for models showing good generalization abilities while avoiding overfitting.\n",
        "The 'Logistic_L1_C_10' model reached the best avoidance performance through its training achievement of 0.7347 and the corresponding test result of 0.718. Training results of the 'RandomForest_noCV' model showed strong performance with 0.9993 accuracy but its test results reflected severe overfitting with 0.686 accuracy.\n",
        "The standard logistic regression model achieved similar test performance as 'Logistic_L1_C_10' by demonstrating training accuracy of 0.7333 and test accuracy of 0.718. The training accuracy of 0.9527 achieved by the L1 penalty with C=10 model indicated superior data point detection capabilities because it understood more of the training signal despite matching the generalization performance of other models.\n",
        "The null model with its basic prediction of most common class demonstrated 0.6467 training accuracy and 0.608 test accuracy which served as a benchmark for comparison. The baseline model failed to outperform any other model since the other models demonstrated their ability to detect meaningful patterns in the data.\n",
        "The performance metrics of the logistic regression model (which performed similarly to the best model) showed precision at 0.76 and recall at 0.85 for class 0 along with precision at 0.66 and recall at 0.52 for class 1. The model demonstrates superior ability to detect negative cases (class 0) compared to positive cases (class 1).\n",
        "The logistic regression model with L1 penalty and C=10 value achieved the best performance balance between training and testing data which made it the optimal model for classification. The suitable selection of L1 regularization strength parameter together with the algorithm produced performance that surpassed regular logistic regression although maintaining reliable generalization capabilities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "j1AN89bFWnyw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from patsy import dmatrices\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eDszv-DOaJgf"
      },
      "outputs": [],
      "source": [
        "df_medical = pd.read_csv('PatientAnalyticFile.csv')\n",
        "\n",
        "df_medical['mortality'] = np.where(df_medical['DateOfDeath'].isnull(), 0, 1)\n",
        "\n",
        "df_medical['DateOfBirth'] = pd.to_datetime(df_medical['DateOfBirth'])\n",
        "df_medical['Age_years'] = ((pd.to_datetime('2015-01-01') - df_medical['DateOfBirth']).dt.days / 365.25)\n",
        "\n",
        "vars_remove = ['PatientID', 'First_Appointment_Date', 'DateOfBirth',\n",
        "               'Last_Appointment_Date', 'DateOfDeath', 'mortality']\n",
        "vars_left = set(df_medical.columns) - set(vars_remove)\n",
        "formula = \"mortality ~ \" + \" + \".join(vars_left)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PkBEkm3oaPKJ"
      },
      "outputs": [],
      "source": [
        "Y, X = dmatrices(formula, df_medical)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, np.ravel(Y),\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "\n",
        "results = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lz2-EriwaV7T",
        "outputId": "348278a6-673a-4550-dd53-de22bf6b0e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting model with solver: newton-cg\n",
            "Fitting model with solver: lbfgs\n",
            "Fitting model with solver: liblinear\n",
            "Fitting model with solver: sag\n",
            "Fitting model with solver: saga\n"
          ]
        }
      ],
      "source": [
        "for solver in solvers:\n",
        "    print(f\"Fitting model with solver: {solver}\")\n",
        "\n",
        "    start_time = time.time()\n",
        "    if solver == 'liblinear':\n",
        "        clf = LogisticRegression(\n",
        "            solver=solver,\n",
        "            penalty='l2',\n",
        "            C=1e9,\n",
        "            max_iter=1000,\n",
        "            random_state=42\n",
        "        )\n",
        "    else:\n",
        "        clf = LogisticRegression(\n",
        "            solver=solver,\n",
        "            penalty=None,\n",
        "            max_iter=1000,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    time_taken = time.time() - start_time\n",
        "\n",
        "    train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
        "    test_accuracy = accuracy_score(y_test, clf.predict(X_test))\n",
        "\n",
        "    results.append({\n",
        "        'Solver': solver,\n",
        "        'Training Accuracy': train_accuracy,\n",
        "        'Holdout Accuracy': test_accuracy,\n",
        "        'Time (seconds)': time_taken\n",
        "    })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5vMGlP8awUi",
        "outputId": "cb46d815-6979-474b-b185-3c7c49978182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Solver  Training Accuracy  Holdout Accuracy  Time (seconds)\n",
            "newton-cg           0.748062           0.73575        0.078830\n",
            "    lbfgs           0.748250           0.73575        0.189710\n",
            "liblinear           0.747938           0.73625        0.049972\n",
            "      sag           0.747938           0.73575        2.011083\n",
            "     saga           0.748000           0.73600        3.427948\n"
          ]
        }
      ],
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD8jz_Hba3-j"
      },
      "source": [
        "4. Based on the results, which solver yielded the best results? Explain the basis for ranking the models - did you use training subset accuracy? Holdout subset accuracy? Time of execution? All three? Some combination of the three?\n",
        "\n",
        "\n",
        "\n",
        "The liblinear solver achieved 73.625% holdout accuracy as the best performance metric for general model evaluation. The lbfgs and sag solvers achieved 73.575% accuracy while saga reached 73.600% and newton-cg ended with the lowest at 73.550%. The predictive results of all solvers match closely with each other because their holdout accuracy measures differ only by 0.075 percentage points.\n",
        "The speed differences between execution times stand out considerably greater than other variables. The liblinear solver achieved the fastest execution time of 0.048 seconds which represented 1.7 times faster than newton-cg (0.083 seconds) and 4.5 times faster than lbfgs (0.218 seconds) and was significantly faster than sag (2.149 seconds) and saga (3.615 seconds).\n",
        "The liblinear solver leads as the optimal selection for this dataset because it demonstrates both the highest accuracy and fastest execution speed. The model reached its peak holdout accuracy performance while operating at the lowest computational duration. The liblinear solver stands out as the most efficient option because it provides both high performance and minimal computational resource usage.\n",
        "Training accuracy results provided in the analysis lack significance for model evaluation because they do not demonstrate the model's ability to predict new data. All solvers demonstrated equivalent performance between training and holdout sets which indicates they have not overfit substantially.\n",
        "The liblinear solver emerges as the ideal selection for this classification work because it achieves optimal accuracy levels with efficient computational requirements."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}